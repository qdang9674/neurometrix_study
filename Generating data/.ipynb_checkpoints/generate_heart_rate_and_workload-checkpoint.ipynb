{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd975397-dbeb-4fdb-bc34-2dc9e12e1b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import time\n",
    "import re\n",
    "from datetime import timedelta\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy import stats\n",
    "import neurokit2 as nk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta# Assuming you have a DataFrame named separated_data with columns 'ecg_data' and 'time_in_seconds'# Define the sampling frequency\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da3fac95-26aa-4884-9ea4-00c5ea8a432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 250  # Sampling frequency# Define the window size and shifting interval in seconds\n",
    "window_size = 30\n",
    "shifting_interval = 1# Initialize lists to store extracted features for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba9f7ad-5ad0-4cdc-a6d6-c066791b3c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84191416-a06b-464e-8926-426588dac456",
   "metadata": {},
   "source": [
    "# Shooting_game Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21283fdf-1ec3-4c29-aebc-e21900e91ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_NAME = \"tack\"\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=\"127.0.0.1\",\n",
    "    port=\"5432\",\n",
    "    database=DB_NAME,\n",
    "    user=\"postgres\",\n",
    "    password=\"postgres\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45897fb8-25aa-40fb-bed1-4caa9a0047fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the SQL query\n",
    "cursor = conn.cursor()\n",
    "sql_query = \"SELECT * FROM tack.sensor_data\"\n",
    "cursor.execute(sql_query)\n",
    "\n",
    "# Fetch all the results\n",
    "columns = [desc[0] for desc in cursor.description]\n",
    "data = cursor.fetchall()\n",
    "ecg_df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "cursor.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "123223f4-858f-4675-8e43-7a301cd3bd09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>computer_name</th>\n",
       "      <th>block_type</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>ecg_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EDFR</td>\n",
       "      <td>mammal_panda</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[1712690031.0352373, 1712690031.0392373, 17126...</td>\n",
       "      <td>[160.0, 170.0, 157.0, 167.0, 155.0, 174.0, 165...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDFR</td>\n",
       "      <td>mammal_panda</td>\n",
       "      <td>block_01</td>\n",
       "      <td>[1712690707.5706294, 1712690707.5746293, 17126...</td>\n",
       "      <td>[673.0, 575.0, 385.0, 125.0, 65.0, 71.0, 87.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EDFR</td>\n",
       "      <td>mammal_panda</td>\n",
       "      <td>block_02</td>\n",
       "      <td>[1712691652.6205168, 1712691652.6245167, 17126...</td>\n",
       "      <td>[204.0, 210.0, 200.0, 206.0, 190.0, 205.0, 195...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EDFR</td>\n",
       "      <td>mammal_panda</td>\n",
       "      <td>block_03</td>\n",
       "      <td>[1712692657.4177406, 1712692657.4217403, 17126...</td>\n",
       "      <td>[168.0, 175.0, 165.0, 177.0, 164.0, 183.0, 177...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EDFR</td>\n",
       "      <td>mammal_panda</td>\n",
       "      <td>block_04</td>\n",
       "      <td>[1712693581.0007808, 1712693581.0047808, 17126...</td>\n",
       "      <td>[156.0, 160.0, 152.0, 203.0, 250.0, 373.0, 537...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>BVCX</td>\n",
       "      <td>mammal_panda</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[1713278800.638756, 1713278800.642756, 1713278...</td>\n",
       "      <td>[130.0, 129.0, 131.0, 133.0, 133.0, 137.0, 142...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>BVCX</td>\n",
       "      <td>mammal_panda</td>\n",
       "      <td>block_01</td>\n",
       "      <td>[1713279427.4931395, 1713279427.4971397, 17132...</td>\n",
       "      <td>[160.0, 130.0, 128.0, 123.0, 131.0, 130.0, 132...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>BVCX</td>\n",
       "      <td>mammal_panda</td>\n",
       "      <td>block_02</td>\n",
       "      <td>[1713280303.034896, 1713280303.0388958, 171328...</td>\n",
       "      <td>[490.0, 558.0, 511.0, 392.0, 277.0, 218.0, 198...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>BVCX</td>\n",
       "      <td>mammal_panda</td>\n",
       "      <td>block_03</td>\n",
       "      <td>[1713281205.8859355, 1713281205.8899355, 17132...</td>\n",
       "      <td>[222.0, 224.0, 220.0, 227.0, 219.0, 225.0, 220...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>BVCX</td>\n",
       "      <td>mammal_panda</td>\n",
       "      <td>block_04</td>\n",
       "      <td>[1713282046.398645, 1713282046.4026449, 171328...</td>\n",
       "      <td>[216.0, 216.0, 216.0, 216.0, 213.0, 215.0, 218...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject_id computer_name block_type  \\\n",
       "0         EDFR  mammal_panda   baseline   \n",
       "1         EDFR  mammal_panda   block_01   \n",
       "2         EDFR  mammal_panda   block_02   \n",
       "3         EDFR  mammal_panda   block_03   \n",
       "4         EDFR  mammal_panda   block_04   \n",
       "..         ...           ...        ...   \n",
       "282       BVCX  mammal_panda   baseline   \n",
       "283       BVCX  mammal_panda   block_01   \n",
       "284       BVCX  mammal_panda   block_02   \n",
       "285       BVCX  mammal_panda   block_03   \n",
       "286       BVCX  mammal_panda   block_04   \n",
       "\n",
       "                                             Timestamp  \\\n",
       "0    [1712690031.0352373, 1712690031.0392373, 17126...   \n",
       "1    [1712690707.5706294, 1712690707.5746293, 17126...   \n",
       "2    [1712691652.6205168, 1712691652.6245167, 17126...   \n",
       "3    [1712692657.4177406, 1712692657.4217403, 17126...   \n",
       "4    [1712693581.0007808, 1712693581.0047808, 17126...   \n",
       "..                                                 ...   \n",
       "282  [1713278800.638756, 1713278800.642756, 1713278...   \n",
       "283  [1713279427.4931395, 1713279427.4971397, 17132...   \n",
       "284  [1713280303.034896, 1713280303.0388958, 171328...   \n",
       "285  [1713281205.8859355, 1713281205.8899355, 17132...   \n",
       "286  [1713282046.398645, 1713282046.4026449, 171328...   \n",
       "\n",
       "                                              ecg_data  \n",
       "0    [160.0, 170.0, 157.0, 167.0, 155.0, 174.0, 165...  \n",
       "1    [673.0, 575.0, 385.0, 125.0, 65.0, 71.0, 87.0,...  \n",
       "2    [204.0, 210.0, 200.0, 206.0, 190.0, 205.0, 195...  \n",
       "3    [168.0, 175.0, 165.0, 177.0, 164.0, 183.0, 177...  \n",
       "4    [156.0, 160.0, 152.0, 203.0, 250.0, 373.0, 537...  \n",
       "..                                                 ...  \n",
       "282  [130.0, 129.0, 131.0, 133.0, 133.0, 137.0, 142...  \n",
       "283  [160.0, 130.0, 128.0, 123.0, 131.0, 130.0, 132...  \n",
       "284  [490.0, 558.0, 511.0, 392.0, 277.0, 218.0, 198...  \n",
       "285  [222.0, 224.0, 220.0, 227.0, 219.0, 225.0, 220...  \n",
       "286  [216.0, 216.0, 216.0, 216.0, 213.0, 215.0, 218...  \n",
       "\n",
       "[287 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = ecg_df['sensor_data'].apply(lambda x: pd.Series(x))\n",
    "ecg_df = pd.concat([ecg_df.drop('sensor_data', axis=1), temp_df.drop('eda_data',axis=1)], axis=1)\n",
    "#ecg_df = ecg_df.explode(['Timestamp','ecg_data'])\n",
    "\n",
    "# #convert to utc\n",
    "# temp_time = (ecg_df['Timestamp'] * 1000000).astype('int64') #convert to microsecond\n",
    "# ecg_df['utc'] = pd.to_datetime(temp_time, unit='us').dt.tz_localize('UTC').dt.tz_convert('Etc/GMT+5')\n",
    "\n",
    "# #convert to number\n",
    "# ecg_df['Timestamp'] = pd.to_numeric(ecg_df['Timestamp'], errors='raise')\n",
    "# ecg_df['ecg_data'] = pd.to_numeric(ecg_df['ecg_data'], errors='raise')\n",
    "\n",
    "ecg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478d41e4-c0fb-4da3-bcbc-7ca4aa464ad8",
   "metadata": {},
   "source": [
    "# Calculate ECG Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cb0aaa2-baaa-42df-88aa-8b02b93b4698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate ECG data function\n",
    "\n",
    "def get_ecg_features(ecg, time_in_sec, fs):\n",
    "    \"\"\"\n",
    "    Compute ECG features from raw ECG signal.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ecg : array-like\n",
    "        Raw ECG signal.\n",
    "    time_in_sec : array-like\n",
    "        Timestamps corresponding to each sample of the ECG signal.\n",
    "    fs : float\n",
    "        Sampling frequency of the ECG signal.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    array\n",
    "        Array of ECG features: [mean heart rate, maximum heart rate, minimum heart rate, heart rate variability].\n",
    "    \"\"\"\n",
    "    try:\n",
    "        b, a = butter(4, (0.25, 25), 'bandpass', fs=fs)\n",
    "        ecg_filt = filtfilt(b, a, ecg, axis=0)\n",
    "        ecg_cleaned = nk.ecg_clean(ecg_filt, sampling_rate=fs)\n",
    "        instant_peaks, rpeaks = nk.ecg_peaks(ecg_cleaned, sampling_rate=fs,method=\"engzeemod2012\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(\"Error processing ECG signal: \" + str(e))\n",
    "\n",
    "    rr_times = time_in_sec[rpeaks['ECG_R_Peaks']]\n",
    "    if len(rr_times) == 0:\n",
    "        raise ValueError(\"No R-peaks detected in ECG signal.\")\n",
    "    \n",
    "    # Assuming d_rr contains the time intervals between successive heartbeats in seconds\n",
    "    d_rr = np.diff(rr_times)\n",
    "    heart_rate = 60 / d_rr\n",
    "    if heart_rate.size == 0:\n",
    "        raise ValueError(\"Error computing heart rate from ECG signal.\")\n",
    "    \n",
    "    valid_heart_rate = heart_rate[~np.isnan(heart_rate)]\n",
    "    z_scores = np.abs(stats.zscore(valid_heart_rate))\n",
    "\n",
    "    # Define a z-score threshold beyond which a value is considered an outlier\n",
    "    z_score_threshold = 2.0\n",
    "\n",
    "    # Remove outliers from the valid_heart_rate array\n",
    "    heart_rate = valid_heart_rate[z_scores <= z_score_threshold]\n",
    "\n",
    "    hr_mean = np.nanmean(heart_rate)\n",
    "    hr_min = np.nanmin(heart_rate)\n",
    "    hr_max = np.nanmax(heart_rate)\n",
    "    d_rr_ms = 1000 * d_rr\n",
    "    d_d_rr_ms = np.diff(d_rr_ms)\n",
    "\n",
    "    valid_d_d_rr_ms = d_d_rr_ms[~np.isnan(d_d_rr_ms)] \n",
    "    z_scores = np.abs(stats.zscore(valid_d_d_rr_ms))\n",
    "    d_d_rr_ms= valid_d_d_rr_ms[z_scores <= z_score_threshold]\n",
    "    heart_rate_variability = np.sqrt(np.nanmean(np.square(d_d_rr_ms)))\n",
    "\n",
    "    # Create a new signal 'ecg_with_rr_intervals' with RR intervals and a 1-second window around each RR interval\n",
    "    ecg_with_rr_intervals = []\n",
    "    ecg_with_rr_intervals_cleaned = []\n",
    "\n",
    "    for rr_interval in rr_times:\n",
    "        start_time = rr_interval - 0.1 # 1 second before the RR interval\n",
    "        end_time = rr_interval + 0.1   # 1 second after the RR interval\n",
    "        indices = np.where((time_in_sec >= start_time) & (time_in_sec <= end_time))[0]\n",
    "\n",
    "        # Validate indices to ensure they are within bounds\n",
    "        indices = indices[(indices >= 0) & (indices < len(ecg))]\n",
    "\n",
    "        if len(indices) > 0:\n",
    "            ecg_with_rr_intervals.extend(ecg[indices])\n",
    "            ecg_with_rr_intervals_cleaned.extend(ecg_cleaned[indices])\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    ecg_with_rr_intervals = np.array(ecg_with_rr_intervals)\n",
    "    ecg_with_rr_intervals_cleaned = np.array(ecg_with_rr_intervals_cleaned)\n",
    "\n",
    "    # Calculate noise power (mean squared amplitude of noise)\n",
    "    signal_power = np.var(ecg_with_rr_intervals)\n",
    "    noise_power = np.var(ecg_with_rr_intervals - ecg_with_rr_intervals_cleaned)\n",
    "\n",
    "    # Calculate noise power (mean squared amplitude of noise)\n",
    "    #signal_power = np.var(ecg)\n",
    "    #noise_power = np.var(ecg - ecg_cleaned)\n",
    "\n",
    "     # Calculate SNR in dB and append it to the array\n",
    "    snr_values = 10 * np.log10(signal_power / noise_power)\n",
    "    \n",
    "    return hr_mean, hr_max, hr_min, heart_rate_variability, snr_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf120825-61f6-4bba-9c16-cf6557709098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a1614fd-4298-4fe5-82bb-4476466c494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#allias this dataFrame to work with Murat code\n",
    "separated_data = ecg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29e2ff08-700d-4252-970c-642ef8a58b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :   EDFR    baseline\n",
      "1 :   EDFR    block_01\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store extracted features for each row\n",
    "hr_mean_lists = []\n",
    "hr_max_lists = []\n",
    "hr_min_lists = []\n",
    "hr_variability_lists = []\n",
    "snr_values_lists = []\n",
    "start_time_lists = []\n",
    "end_time_lists = []\n",
    "\n",
    "for index, row in separated_data.iterrows():\n",
    "    print(index, ':  ',row['subject_id'], '  ', row['block_type'])\n",
    "    ecg = np.array(row['ecg_data'])  # Convert ecg_data to NumPy array\n",
    "    #timestamps = np.array(row['time_in_seconds'])  # Convert time_in_seconds to NumPy array    i = 0\n",
    "    timestamps = np.array(row['Timestamp'])  # Convert time_in_seconds to NumPy array    i = 0\n",
    "    # Initialize lists to store features for the current row\n",
    "    hr_mean_list = []\n",
    "    hr_max_list = []\n",
    "    hr_min_list = []\n",
    "    hr_variability_list = []\n",
    "    snr_values_list = []    # Iterate through the ECG data in 30-second windows with 1-second overlap\n",
    "    start_time_list = []\n",
    "    end_time_list = []\n",
    "    \n",
    "    for start_time in range(0, len(ecg) - window_size * fs, shifting_interval * fs):\n",
    "        end_time = start_time + window_size * fs\n",
    "        window_ecg = ecg[start_time:end_time]\n",
    "        window_timestamps = timestamps[start_time:end_time]        # Check for NaN values in the window_ecg and window_timestamps\n",
    "\n",
    "        \n",
    "        nan_ecg_indices = np.isnan(window_ecg)\n",
    "        nan_timestamps_indices = np.isnan(window_timestamps)\n",
    "        if nan_ecg_indices.any() or nan_timestamps_indices.any():\n",
    "            # Interpolate NaN values if present\n",
    "            if nan_ecg_indices.any():\n",
    "                window_ecg = np.interp(np.arange(len(window_ecg)), np.where(~nan_ecg_indices)[0], window_ecg[~nan_ecg_indices])\n",
    "            if nan_timestamps_indices.any():\n",
    "                window_timestamps = np.interp(np.arange(len(window_timestamps)), np.where(~nan_timestamps_indices)[0], window_timestamps[~nan_timestamps_indices])\n",
    "        try:\n",
    "            # Call your get_ecg_features function and extract features\n",
    "            features = get_ecg_features(window_ecg, window_timestamps, fs)            # Check if features is not None before appending\n",
    "            if features is not None:\n",
    "                #i = i + 1                # Append the extracted features to the respective lists for the current row\n",
    "                hr_mean_list.append(features[0])\n",
    "                hr_max_list.append(features[1])\n",
    "                hr_min_list.append(features[2])\n",
    "                hr_variability_list.append(features[3])\n",
    "                snr_values_list.append(features[4])\n",
    "                start_time_list.append(timestamps[start_time])\n",
    "                end_time_list.append(timestamps[end_time])\n",
    "                \n",
    "        except ValueError as e:\n",
    "            # Handle errors or skip this window in case of an error\n",
    "            print(f\"Error in feature extraction: {e}\")\n",
    "            continue    # Append the lists for the current row to the corresponding lists for all rows\n",
    "\n",
    "    \n",
    "    hr_mean_lists.append(hr_mean_list)\n",
    "    hr_max_lists.append(hr_max_list)\n",
    "    hr_min_lists.append(hr_min_list)\n",
    "    hr_variability_lists.append(hr_variability_list)\n",
    "    snr_values_lists.append(snr_values_list)# Add the lists as new columns in the separated_data DataFrame\n",
    "    start_time_lists.append(start_time_list)\n",
    "    end_time_lists.append(end_time_list)\n",
    "\n",
    "separated_data['hr_mean'] = hr_mean_lists\n",
    "separated_data['hr_max'] = hr_max_lists\n",
    "separated_data['hr_min'] = hr_min_lists\n",
    "separated_data['heart_rate_variability'] = hr_variability_lists\n",
    "separated_data['snr_values'] = snr_values_lists\n",
    "separated_data['start_time'] = start_time_lists\n",
    "separated_data['end_time'] = end_time_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2be3f122-4b81-4d15-80a0-343ea23ef77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>computer_name</th>\n",
       "      <th>block_type</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>ecg_data</th>\n",
       "      <th>hr_mean</th>\n",
       "      <th>hr_max</th>\n",
       "      <th>hr_min</th>\n",
       "      <th>heart_rate_variability</th>\n",
       "      <th>snr_values</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EDFR</td>\n",
       "      <td>mammal_panda</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[1712690031.0352373, 1712690031.0392373, 17126...</td>\n",
       "      <td>[160.0, 170.0, 157.0, 167.0, 155.0, 174.0, 165...</td>\n",
       "      <td>[90.71884287767276, 90.53768858069103, 90.2537...</td>\n",
       "      <td>[102.04088881536292, 102.04088881536292, 102.0...</td>\n",
       "      <td>[84.26964734483123, 84.26964734483123, 84.2696...</td>\n",
       "      <td>[16.399785026557797, 15.889890099634755, 14.00...</td>\n",
       "      <td>[6.4596347987266025, 6.469030541974598, 6.4558...</td>\n",
       "      <td>[1712690031.0352373, 1712690032.0352373, 17126...</td>\n",
       "      <td>[1712690061.0352373, 1712690062.0352373, 17126...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDFR</td>\n",
       "      <td>mammal_panda</td>\n",
       "      <td>block_01</td>\n",
       "      <td>[1712690707.5706294, 1712690707.5746293, 17126...</td>\n",
       "      <td>[673.0, 575.0, 385.0, 125.0, 65.0, 71.0, 87.0,...</td>\n",
       "      <td>[94.28375271973553, 94.15796232666496, 94.1161...</td>\n",
       "      <td>[103.44820442159282, 102.73970656557286, 103.4...</td>\n",
       "      <td>[83.33333002196431, 83.33333002196431, 83.3333...</td>\n",
       "      <td>[19.585919745480158, 19.49605824648644, 19.714...</td>\n",
       "      <td>[6.498243535103615, 6.647450638921232, 6.66762...</td>\n",
       "      <td>[1712690707.5706294, 1712690708.5706294, 17126...</td>\n",
       "      <td>[1712690737.5706294, 1712690738.5706294, 17126...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id computer_name block_type  \\\n",
       "0       EDFR  mammal_panda   baseline   \n",
       "1       EDFR  mammal_panda   block_01   \n",
       "\n",
       "                                           Timestamp  \\\n",
       "0  [1712690031.0352373, 1712690031.0392373, 17126...   \n",
       "1  [1712690707.5706294, 1712690707.5746293, 17126...   \n",
       "\n",
       "                                            ecg_data  \\\n",
       "0  [160.0, 170.0, 157.0, 167.0, 155.0, 174.0, 165...   \n",
       "1  [673.0, 575.0, 385.0, 125.0, 65.0, 71.0, 87.0,...   \n",
       "\n",
       "                                             hr_mean  \\\n",
       "0  [90.71884287767276, 90.53768858069103, 90.2537...   \n",
       "1  [94.28375271973553, 94.15796232666496, 94.1161...   \n",
       "\n",
       "                                              hr_max  \\\n",
       "0  [102.04088881536292, 102.04088881536292, 102.0...   \n",
       "1  [103.44820442159282, 102.73970656557286, 103.4...   \n",
       "\n",
       "                                              hr_min  \\\n",
       "0  [84.26964734483123, 84.26964734483123, 84.2696...   \n",
       "1  [83.33333002196431, 83.33333002196431, 83.3333...   \n",
       "\n",
       "                              heart_rate_variability  \\\n",
       "0  [16.399785026557797, 15.889890099634755, 14.00...   \n",
       "1  [19.585919745480158, 19.49605824648644, 19.714...   \n",
       "\n",
       "                                          snr_values  \\\n",
       "0  [6.4596347987266025, 6.469030541974598, 6.4558...   \n",
       "1  [6.498243535103615, 6.647450638921232, 6.66762...   \n",
       "\n",
       "                                          start_time  \\\n",
       "0  [1712690031.0352373, 1712690032.0352373, 17126...   \n",
       "1  [1712690707.5706294, 1712690708.5706294, 17126...   \n",
       "\n",
       "                                            end_time  \n",
       "0  [1712690061.0352373, 1712690062.0352373, 17126...  \n",
       "1  [1712690737.5706294, 1712690738.5706294, 17126...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4014d66-2930-4dba-8840-c7ee90d61573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>computer_name</th>\n",
       "      <th>block_type</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>ecg_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EDFR</td>\n",
       "      <td>mammal_panda</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[1712690031.0352373, 1712690031.0392373, 17126...</td>\n",
       "      <td>[160.0, 170.0, 157.0, 167.0, 155.0, 174.0, 165...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDFR</td>\n",
       "      <td>mammal_panda</td>\n",
       "      <td>block_01</td>\n",
       "      <td>[1712690707.5706294, 1712690707.5746293, 17126...</td>\n",
       "      <td>[673.0, 575.0, 385.0, 125.0, 65.0, 71.0, 87.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EDFR</td>\n",
       "      <td>mammal_panda</td>\n",
       "      <td>block_02</td>\n",
       "      <td>[1712691652.6205168, 1712691652.6245167, 17126...</td>\n",
       "      <td>[204.0, 210.0, 200.0, 206.0, 190.0, 205.0, 195...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EDFR</td>\n",
       "      <td>mammal_panda</td>\n",
       "      <td>block_03</td>\n",
       "      <td>[1712692657.4177406, 1712692657.4217403, 17126...</td>\n",
       "      <td>[168.0, 175.0, 165.0, 177.0, 164.0, 183.0, 177...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EDFR</td>\n",
       "      <td>mammal_panda</td>\n",
       "      <td>block_04</td>\n",
       "      <td>[1712693581.0007808, 1712693581.0047808, 17126...</td>\n",
       "      <td>[156.0, 160.0, 152.0, 203.0, 250.0, 373.0, 537...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>BVCX</td>\n",
       "      <td>mammal_panda</td>\n",
       "      <td>baseline</td>\n",
       "      <td>[1713278800.638756, 1713278800.642756, 1713278...</td>\n",
       "      <td>[130.0, 129.0, 131.0, 133.0, 133.0, 137.0, 142...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>BVCX</td>\n",
       "      <td>mammal_panda</td>\n",
       "      <td>block_01</td>\n",
       "      <td>[1713279427.4931395, 1713279427.4971397, 17132...</td>\n",
       "      <td>[160.0, 130.0, 128.0, 123.0, 131.0, 130.0, 132...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>BVCX</td>\n",
       "      <td>mammal_panda</td>\n",
       "      <td>block_02</td>\n",
       "      <td>[1713280303.034896, 1713280303.0388958, 171328...</td>\n",
       "      <td>[490.0, 558.0, 511.0, 392.0, 277.0, 218.0, 198...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>BVCX</td>\n",
       "      <td>mammal_panda</td>\n",
       "      <td>block_03</td>\n",
       "      <td>[1713281205.8859355, 1713281205.8899355, 17132...</td>\n",
       "      <td>[222.0, 224.0, 220.0, 227.0, 219.0, 225.0, 220...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>BVCX</td>\n",
       "      <td>mammal_panda</td>\n",
       "      <td>block_04</td>\n",
       "      <td>[1713282046.398645, 1713282046.4026449, 171328...</td>\n",
       "      <td>[216.0, 216.0, 216.0, 216.0, 213.0, 215.0, 218...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject_id computer_name block_type  \\\n",
       "0         EDFR  mammal_panda   baseline   \n",
       "1         EDFR  mammal_panda   block_01   \n",
       "2         EDFR  mammal_panda   block_02   \n",
       "3         EDFR  mammal_panda   block_03   \n",
       "4         EDFR  mammal_panda   block_04   \n",
       "..         ...           ...        ...   \n",
       "282       BVCX  mammal_panda   baseline   \n",
       "283       BVCX  mammal_panda   block_01   \n",
       "284       BVCX  mammal_panda   block_02   \n",
       "285       BVCX  mammal_panda   block_03   \n",
       "286       BVCX  mammal_panda   block_04   \n",
       "\n",
       "                                             Timestamp  \\\n",
       "0    [1712690031.0352373, 1712690031.0392373, 17126...   \n",
       "1    [1712690707.5706294, 1712690707.5746293, 17126...   \n",
       "2    [1712691652.6205168, 1712691652.6245167, 17126...   \n",
       "3    [1712692657.4177406, 1712692657.4217403, 17126...   \n",
       "4    [1712693581.0007808, 1712693581.0047808, 17126...   \n",
       "..                                                 ...   \n",
       "282  [1713278800.638756, 1713278800.642756, 1713278...   \n",
       "283  [1713279427.4931395, 1713279427.4971397, 17132...   \n",
       "284  [1713280303.034896, 1713280303.0388958, 171328...   \n",
       "285  [1713281205.8859355, 1713281205.8899355, 17132...   \n",
       "286  [1713282046.398645, 1713282046.4026449, 171328...   \n",
       "\n",
       "                                              ecg_data  \n",
       "0    [160.0, 170.0, 157.0, 167.0, 155.0, 174.0, 165...  \n",
       "1    [673.0, 575.0, 385.0, 125.0, 65.0, 71.0, 87.0,...  \n",
       "2    [204.0, 210.0, 200.0, 206.0, 190.0, 205.0, 195...  \n",
       "3    [168.0, 175.0, 165.0, 177.0, 164.0, 183.0, 177...  \n",
       "4    [156.0, 160.0, 152.0, 203.0, 250.0, 373.0, 537...  \n",
       "..                                                 ...  \n",
       "282  [130.0, 129.0, 131.0, 133.0, 133.0, 137.0, 142...  \n",
       "283  [160.0, 130.0, 128.0, 123.0, 131.0, 130.0, 132...  \n",
       "284  [490.0, 558.0, 511.0, 392.0, 277.0, 218.0, 198...  \n",
       "285  [222.0, 224.0, 220.0, 227.0, 219.0, 225.0, 220...  \n",
       "286  [216.0, 216.0, 216.0, 216.0, 213.0, 215.0, 218...  \n",
       "\n",
       "[287 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0c88bc-caed-438f-b05b-bda824b9d73b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72dfd34-853c-491b-89f3-0bc88ac014fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd833e54-47dc-40cd-b6ff-7d8a5e37da58",
   "metadata": {},
   "source": [
    "## Calculate Workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e31f816c-45d0-4442-a44e-67e4050bc54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_model_path = r\".\\Mural_ECG_model\\model\"\n",
    "ecg_model = tf.saved_model.load(ecg_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af922b4f-311e-494a-a84e-af36689ab3a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['EDFR', 'HGFD', 'JHGF', 'LKMN', 'LPDW', 'MJUY', 'SPKZR', 'SVTZM',\n",
       "       'TYDF', 'WZXE', 'XZPT', 'ZXCV', 'ZXWE', 'ZYXW', 'HJKL', 'HPLX',\n",
       "       'LKPW', 'LPZV', 'LRTB', 'MJKL', 'MNOP', 'OPKJ', 'QAXY', 'QXZW',\n",
       "       'SBTBT', 'STWXJ', 'VFTY', 'XUYP', 'DFGH', 'DFZX', 'FTLD', 'GHJK',\n",
       "       'MTYH', 'NMBV', 'PKJH', 'QWER', 'QWRT', 'RQWE', 'SNMVN', 'SXVBN',\n",
       "       'TYZX', 'ZRTY', 'CVBN', 'DKLQ', 'GTYU', 'JKLZ', 'KJHG', 'MNBW',\n",
       "       'QPOI', 'SBQRG', 'SRKLP', 'UYGH', 'VBNM', 'VNPL', 'WERT', 'LKJH',\n",
       "       'QAZW', 'XCVH', 'BVCX'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_HR_CUTOFF = 250\n",
    "MIN_HR_CUTOFF = 25\n",
    "SNR_CUTOFF = 4\n",
    "SUBJECT_LIST = ecg_df['subject_id'].unique()\n",
    "SUBJECT_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ccd11-31b5-4af2-a572-06028e4a7573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cecd0961-caa7-4fc8-b888-41b5a1af013f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'hr_mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\shooting_game\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\.conda\\envs\\shooting_game\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\.conda\\envs\\shooting_game\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'hr_mean'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m baseline_row \u001b[38;5;241m=\u001b[39m temp_df[temp_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblock_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbaseline\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#fit_scaler\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m mean_scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\u001b[38;5;241m.\u001b[39mfit(np\u001b[38;5;241m.\u001b[39marray(\u001b[43mbaseline_row\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhr_mean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      7\u001b[0m max_scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\u001b[38;5;241m.\u001b[39mfit(np\u001b[38;5;241m.\u001b[39marray(baseline_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhr_max\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      8\u001b[0m min_scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\u001b[38;5;241m.\u001b[39mfit(np\u001b[38;5;241m.\u001b[39marray(baseline_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhr_min\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\.conda\\envs\\shooting_game\\lib\\site-packages\\pandas\\core\\series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1012\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\shooting_game\\lib\\site-packages\\pandas\\core\\series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1116\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32m~\\.conda\\envs\\shooting_game\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'hr_mean'"
     ]
    }
   ],
   "source": [
    "for cur_subject in SUBJECT_LIST:\n",
    "    temp_df = ecg_df[ecg_df['subject_id'] == cur_subject]\n",
    "    baseline_row = temp_df[temp_df['block_type'] == 'baseline'].iloc[0]\n",
    "    \n",
    "    #fit_scaler\n",
    "    mean_scaler = StandardScaler().fit(np.array(baseline_row['hr_mean']).reshape(-1,1))\n",
    "    max_scaler = StandardScaler().fit(np.array(baseline_row['hr_max']).reshape(-1,1))\n",
    "    min_scaler = StandardScaler().fit(np.array(baseline_row['hr_min']).reshape(-1,1))\n",
    "    hrv_scaler = StandardScaler().fit(np.array(baseline_row['heart_rate_variability']).reshape(-1,1))\n",
    "    \n",
    "    max_hr_cutoff = (MAX_HR_CUTOFF - max_scaler.mean_[0]) / max_scaler.var_[0]   #convert heart rate cuttoff value to standardlize value\n",
    "    min_hr_cutoff = (MIN_HR_CUTOFF - min_scaler.mean_[0]) / min_scaler.var_[0]   #convert heart rate cuttoff value to standardlize value\n",
    "\n",
    "    print(max_hr_cutoff, '  ',min_hr_cutoff)\n",
    "    for index, row in temp_df.iterrows():\n",
    "        print(index, ':  ',row['subject_id'], '  ', row['block_type'], end = '  ')\n",
    "        if len(row['hr_mean']) < 2:\n",
    "            print(\"\\n Data unavailible, Continue\")\n",
    "            continue\n",
    "            \n",
    "        #tranform data\n",
    "        mean_scaled = mean_scaler.transform(np.array(row['hr_mean']).reshape(-1,1))\n",
    "        max_scaled = max_scaler.transform(np.array(row['hr_max']).reshape(-1,1))\n",
    "        min_scaled = min_scaler.transform(np.array(row['hr_min']).reshape(-1,1))\n",
    "        hrv_scaled = hrv_scaler.transform(np.array(row['heart_rate_variability']).reshape(-1,1))\n",
    "    \n",
    "    \n",
    "        #predicting workload\n",
    "        workload_list = []\n",
    "        for current_data,current_snr in zip(zip(mean_scaled, max_scaled, min_scaled, hrv_scaled), row['snr_values']):\n",
    "            \n",
    "            current_sample = np.array(current_data).reshape(1,-1)\n",
    "            #santize check\n",
    "            if (current_sample[0][1] > max_hr_cutoff) or (current_sample[0][2] < min_hr_cutoff) or current_snr < (SNR_CUTOFF):\n",
    "                print(\"\\n Invalid heart_rate: \", current_sample[0][1], \"  \", current_sample[0][2], \"  \", current_snr)\n",
    "                workload_list.append([[np.nan]])\n",
    "                continue\n",
    "\n",
    "            prediction = ecg_model(current_sample)\n",
    "            workload_list.append(prediction)\n",
    "    \n",
    "        #add workload to dataFrame\n",
    "        if len(workload_list) < 0:\n",
    "            print(\"No workload data\")\n",
    "            continue\n",
    "        mask = (ecg_df['subject_id'] == row['subject_id']) & (ecg_df['block_type'] == row['block_type'])\n",
    "        print(ecg_df.loc[mask].shape)\n",
    "        ecg_df.loc[mask,'workload'] = str(np.array(workload_list).reshape(-1).tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e47c01-1fc5-4180-9c73-9d05a0e5761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6500964a-768d-4a1e-9a7a-bb0f715f1396",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_df.drop([\"Timestamp\",\"ecg_data\"],axis=1).to_csv(\"Shooting_game_heart_rate.csv\",index=False)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a9cc3c-ca0e-4755-94a7-eda49f04c011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46958000-e2f7-4d94-904b-1ff816fe79f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
